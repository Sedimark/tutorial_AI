{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "As part of the SEDIMARK toolbox that Users will use for configuring AI and Data Processing pipelines for their use case, AI tasks such as forecasting are made readily available for inferencing on Data Assets. Time series forecasting has a wide range of applications across various fields, including financial market prediction, weather forecasting, and traffic flow prediction.\n",
    "\n",
    "In this tutorial, we will use Python to demonstrate the basic AI workflow for time series forecasting, specifically focusing on temperature forecasting for agriculture use cases. Accurate temperature forecasting is crucial for agriculture as it helps farmers plan their activities, manage crops, and optimize yields."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Environment Setup\n",
    "\n",
    "We need to install some toolboxes and libraries for this experiment. Therefore, please copy and use the below command in your python terminal:\n",
    "\n",
    "    pip install numpy pandas matplotlib scikit-learn torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing\n",
    "\n",
    "In this section, we generate the simulation data and apply the preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Generate sample data\n",
    "date_rng = pd.date_range(start='2023-01-01', end='2023-06-30', freq='D')\n",
    "df = pd.DataFrame(date_rng, columns=['date'])\n",
    "df['temperature'] = np.random.randint(20, 35, size=(len(date_rng)))\n",
    "\n",
    "# Set date as index\n",
    "df.set_index('date', inplace=True)\n",
    "\n",
    "# Visualize data\n",
    "df['temperature'].plot(figsize=(12, 6), title='Temperature Time Series')\n",
    "plt.show()\n",
    "\n",
    "# Normalize data\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "df['temperature_scaled'] = scaler.fit_transform(df['temperature'].values.reshape(-1, 1))\n",
    "\n",
    "# Split into training and testing sets\n",
    "train_size = int(len(df) * 0.8)\n",
    "train, test = df[:train_size], df[train_size:]\n",
    "\n",
    "# Create dataset for Transformer\n",
    "def create_dataset(data, time_step=1):\n",
    "    X, Y = [], []\n",
    "    for i in range(len(data) - time_step - 1):\n",
    "        X.append(data[i:(i + time_step), 0])\n",
    "        Y.append(data[i + time_step, 0])\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "time_step = 10\n",
    "X_train, y_train = create_dataset(train['temperature_scaled'].values, time_step)\n",
    "X_test, y_test = create_dataset(test['temperature_scaled'].values, time_step)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "import torch\n",
    "X_train = torch.tensor(X_train.reshape(X_train.shape[0], time_step, 1), dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test.reshape(X_test.shape[0], time_step, 1), dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Build the Simple Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, num_heads, d_model, num_encoder_layers, num_decoder_layers, dff):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=num_heads, dim_feedforward=dff)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=num_encoder_layers)\n",
    "        self.decoder_layer = nn.TransformerDecoderLayer(d_model=d_model, nhead=num_heads, dim_feedforward=dff)\n",
    "        self.transformer_decoder = nn.TransformerDecoder(self.decoder_layer, num_layers=num_decoder_layers)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.dense1 = nn.Linear(d_model * time_step, dff)\n",
    "        self.dense2 = nn.Linear(dff, 1)\n",
    "\n",
    "    def forward(self, src):\n",
    "        encoder_output = self.transformer_encoder(src)\n",
    "        decoder_output = self.transformer_decoder(encoder_output, encoder_output)\n",
    "        flatten_output = self.flatten(decoder_output)\n",
    "        dense_output = self.dense1(flatten_output)\n",
    "        output = self.dense2(dense_output)\n",
    "        return output\n",
    "\n",
    "# Hyperparameters\n",
    "num_heads = 2\n",
    "d_model = 64\n",
    "num_encoder_layers = 2\n",
    "num_decoder_layers = 2\n",
    "dff = 128\n",
    "\n",
    "# Create model\n",
    "model = TransformerModel(num_heads, d_model, num_encoder_layers, num_decoder_layers, dff)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train model\n",
    "num_epochs = 50\n",
    "batch_size = 64\n",
    "train_loader = torch.utils.data.DataLoader(dataset=list(zip(X_train, y_train)), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs.squeeze(), batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    train_predict = model(X_train).squeeze().numpy()\n",
    "    test_predict = model(X_test).squeeze().numpy()\n",
    "\n",
    "# Inverse transform the predictions\n",
    "train_predict = scaler.inverse_transform(train_predict.reshape(-1, 1))\n",
    "test_predict = scaler.inverse_transform(test_predict.reshape(-1, 1))\n",
    "y_train = scaler.inverse_transform(y_train.reshape(-1, 1))\n",
    "y_test = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Calculate RMSE\n",
    "train_score = math.sqrt(mean_squared_error(y_train, train_predict))\n",
    "test_score = math.sqrt(mean_squared_error(y_test, test_predict))\n",
    "print(f'Train Score: {train_score} RMSE')\n",
    "print(f'Test Score: {test_score} RMSE')\n",
    "\n",
    "# Visualize predictions\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(df['temperature'], label='Actual Data')\n",
    "plt.plot(df.index[time_step:train_size], train_predict, label='Train Predict')\n",
    "plt.plot(df.index[train_size+time_step+1:], test_predict, label='Test Predict')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Conclusion\n",
    "\n",
    "This tutorial demonstrates how to use a basic Transformer model for time series forecasting, specifically for temperature prediction in agriculture. Accurate temperature forecasting is essential for agricultural planning and decision-making, helping farmers optimize crop management and improve yields. Through this example, readers can gain a fundamental understanding of applying Transformers to time series forecasting and further research and optimize the model for better prediction performance.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
